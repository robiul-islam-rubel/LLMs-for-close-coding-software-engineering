{"0": {"meta": {"StartDate": "2023-03-01 16:33:34", "EndDate": "2023-03-01 17:01:03", "Status": "IP Address", "Progress": "100", "Duration": "1649", "Finished": "True", "RecordedDate": "2023-03-01 17:01:04", "ResponseID": "R_snX1LGF2NUe2M6Z", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Environment in which the model was trained in", "Model structure / architecture", "Model hyperparameters", "Known model/data defects", "Potential model biases", "Potential fairness issues", "Optimizers, loss functions, etc.", "Description of the training data", "Description of the validation and testing data", "Runtime performance requirements", "Data (pre-)processing techniques", "Presence of Personally Identifiable Information", "Model version", "Model description", "Creation / building time", "Model license", "Data version", "System dependencies", "Others (please specify)"], "other": "Specific model definitions - say I'm working in PyTorch and want to use someone else's pretrained weights. I should have access to the exact model definition used for the model. If someone is forced to reverse engineer the model, small details may be incorrect, leading to errors. For example, classification heads for image classifiers are usually either in the order of AvgPool2d -> norm -> fc or norm->AvgPool2d -> fc. Reversing the order has no impact on the loading of the model weights, but leads to differences in model performance.\nValidation procedures are also potentially in need of documentation, specifically the image preprocessing pipeline used during the validation phase of image classification models should be fully documented such that it is replicable from scratch. I know that cropping procedures, resizing interpolation algorithms, and other small and often-overlooked aspects of deep learning code can have effects on the results."}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "3", "2": "1", "3": "2", "4": "4", "5": "5", "6": "6", "other": ""}, "AI7": "I think that a push and shift toward increased documentation and the use of AIBOMs, or at least some of their components, will help report dependencies. This can be seen in the past 5 or so years, where there is a large increase of paper authors publishing code and including a list of hyperparameters, training recipes, software package versions, hardware used, and other details about experiments in papers. I think that as top venues start to require more of these documentations, there will be a shift to where publishing AIBOMs becomes the norm."}, "databom_fields": {"D1": "Agree", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Dataset authors / creators", "Data labelers / taggers", "Procedure for data collection and curation", "Presence of Personally Identifiable Information", "Dataset statistics", "Dataset version", "Dataset license", "Dataset description", "Version description (dataset change log)", "Creation time", "Known data biases", "Known vulnerabilities and issues", "Unique identifier", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size", "Others (please specify)"], "other": "Known problems in a dataset ie. corrupt images, tips for using the dataset, including prewritten codebases for working with the data ie. repository of pytorch dataset definitions and sample training scripts for use with a newly proposed image dataset, visualization/data exporation tools, hosted access ie. huggingface datasets"}, "D4": {"answers": "No", "other": ""}, "D5": "If you are proposing a dataset, make a dataBOM along with it. if you are using data, link to the dataset using a resource that also has the dataBOM accessible. If you are doing any sort of training in the process of working with data, create an AIBOM describing this training. I think that they should be separate overall, with each serving to describe a different category of things.", "D6": {"1": "3", "2": "1", "3": "2", "4": "4", "5": "5", "other": ""}, "D7": "Sample code will make data easier to work with, as will hosting. I should not have to go a scrape a dataset using a csv of flickr URLs.", "D8": "Some of the fields that would ideally be present are difficult to complete, requiring domain specific knowledge. If I'm good with image models and happen to also want to propose a new dataset, it is difficult for me alone to do all the analysis to create a full DataBOM. I will need people experienced in different domains, such as ethics, data science, and data visualization.", "D9": "again, by making a communitywide push for these thing. I believe that the neurips dataset track requires a dataset card to be submitted alongside the paper, which includes some basic parts of a dataBOM. Expanding this requirement and the contends of this dataset card should help increase the use of DataBOMs."}, "challenges": {"C1": "increased reproducibility, easier iteration on previous works, more accessible resources, earlier detection of weaknesses/vulnerabilities.", "C2": "Time consuming, requires developers to write documentation, may require domain specific knowledge and specific or niche skillsets", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "I think they should echo the latest legal stances from different jurisdictions, as well as any personal opinions/objections the authors may have to particular uses of a dataset."}, "demographics": {"Q1": "2", "Q2": {"answers": "Other (please specify)", "other": "researcher"}, "Q3": {"answers": "Other (please specify)", "other": "Some college but as part of my high school education"}, "Q4": {"answers": ["Python", "Java", "C / C++"], "other": ""}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open source only", "Q7": "content retrieval", "Q8": "No", "Q9": "Yes, informal", "Q10": "Never"}}, "1": {"meta": {"StartDate": "2023-03-01 17:01:43", "EndDate": "2023-03-01 17:20:36", "Status": "IP Address", "Progress": "100", "Duration": "1132", "Finished": "True", "RecordedDate": "2023-03-01 17:20:36", "ResponseID": "R_2nSZ6Uk4gpCWUxP", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Optimizers, loss functions, etc.", "Description of the training data", "Description of the validation and testing data", "Data (pre-)processing techniques", "Others (please specify)"], "other": "The loss function is the most important. The loss function is also directly related to the data it was trained on. "}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "6", "2": "1", "3": "4", "4": "5", "5": "3", "6": "2", "other": "Written into the model parameters"}, "AI7": "I can only think of being able to reproduce the model to be completely sure of how it was created."}, "databom_fields": {"D1": "Neutral", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Dataset authors / creators", "Data labelers / taggers", "Procedure for data collection and curation", "Presence of Personally Identifiable Information", "Dataset version", "Dataset license", "Dataset description", "Version description (dataset change log)", "Creation time"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "The data is what defines what the model will learn. So knowing about the data half the story of a model.", "D6": {"1": "4", "2": "1", "3": "2", "4": "3", "5": "5", "other": ""}, "D7": "I think people already try to document their datasets. having a structure will help them to not forget to detail specific aspects of the dataset. Like Nature Scientific Data provides a structure that is very useful.", "D8": "Ridged requirements are always annoying when they don't apply to your work. Enforcing a standard will likely hurt innovation more than help it.", "D9": "Create a legal liability for misrepresenting data."}, "challenges": {"C1": "It will provide structure to help people document their work.", "C2": "It is hard to anticipate how an imposed structure will hinder someones work.", "C3": {"answers": "No", "other": ""}, "C4": "", "C5": {"answers": "No", "other": ""}, "C6": "", "C7": "If the AIBOM specifies that there is no issue with licensed material and there turns out to be an issue, then the legal liability will rest with the creator of the AIBOM who misrepresented the claims."}, "demographics": {"Q1": "8", "Q2": {"answers": "Other (please specify)", "other": "Researcher"}, "Q3": {"answers": "Doctoral Degree", "other": ""}, "Q4": {"answers": ["Python", "Java", "C / C++", "Javascript"], "other": ""}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open and closed source", "Q7": "Healthcare, security, conservation, assistive technology", "Q8": "Yes, formal", "Q9": "Yes, informal", "Q10": "Quarterly"}}, "2": {"meta": {"StartDate": "2023-03-01 17:13:09", "EndDate": "2023-03-01 17:20:56", "Status": "IP Address", "Progress": "100", "Duration": "467", "Finished": "True", "RecordedDate": "2023-03-01 17:20:57", "ResponseID": "R_3DbEw6tOraj96Gs", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Environment in which the model was trained in", "Model structure / architecture", "Model hyperparameters", "Model parameters", "Known model/data defects", "Unique model identifier", "Optimizers, loss functions, etc.", "Description of the training data", "Description of the validation and testing data", "Runtime performance requirements", "Data (pre-)processing techniques", "Presence of Personally Identifiable Information", "Model version", "Model description", "Creation / building time", "Model license", "Data version", "System dependencies"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "Yes (please list them)", "other": "HuggingFace does this to a certain degree when you train models with their Trainer and push them to the hub with push_to_hub. The README is populated with a lot of information that was mentioned in the previous question. "}, "AI6": {"1": "4", "2": "1", "3": "2", "4": "5", "5": "3", "6": "6", "other": ""}, "AI7": "Should contain virtually everything mentioned in the last question. Even then reproducing results could be tricky."}, "databom_fields": {"D1": "Agree", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Procedure for data collection and curation", "Presence of Personally Identifiable Information", "Dataset statistics", "Dataset version", "Dataset license", "Dataset description", "Version description (dataset change log)", "Creation time", "Known data biases", "Known vulnerabilities and issues", "Unique identifier", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size"], "other": ""}, "D4": {"answers": "Yes (please list them)", "other": "Again, HuggingFace does this to a certain degree with the dataset cards on the HF hub"}, "D5": "You would need both to reproduce results from an ML system, so they should be considered complementary.", "D6": {"1": "3", "2": "1", "3": "2", "4": "4", "5": "5", "other": ""}, "D7": "Often data preprocessing steps that are critical for good performance / reproduction of results go unmentioned in papers. A DataBOM could help make these more transparent.", "D8": "Getting dataset creators to fill them in. Should be automated as much as possible.", "D9": "Perhaps requiring them to publish papers in conferences and journals."}, "challenges": {"C1": "Similar answer to DataBOMs.", "C2": "Similar answer to DataBOMs.", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "Maybe provide a license information for each data source. Also provide information allowing data owners to opt out from scrapping."}, "demographics": {"Q1": "5", "Q2": {"answers": "Data scientist", "other": ""}, "Q3": {"answers": "Doctoral Degree", "other": ""}, "Q4": {"answers": ["Python"], "other": ""}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open source only", "Q7": "Mainly healthcare and biology", "Q8": "No", "Q9": "No", "Q10": "Annually"}}, "3": {"meta": {"StartDate": "2023-03-01 23:14:51", "EndDate": "2023-03-01 23:36:51", "Status": "IP Address", "Progress": "100", "Duration": "1320", "Finished": "True", "RecordedDate": "2023-03-01 23:36:52", "ResponseID": "R_3kdkXujBLUZKhh0", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Environment in which the model was trained in", "Optimizers, loss functions, etc.", "Description of the training data", "Data (pre-)processing techniques", "Presence of Personally Identifiable Information", "Model license", "Data version", "System dependencies"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "3", "2": "1", "3": "2", "4": "5", "5": "4", "6": "6", "other": ""}, "AI7": "Having a sort of certification board or community, where open source AI software submit their projects for 3rd party assessment."}, "databom_fields": {"D1": "Agree", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Dataset authors / creators", "Presence of Personally Identifiable Information", "Dataset statistics", "Dataset version", "Version description (dataset change log)", "Creation time", "Known data biases", "Known vulnerabilities and issues", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "Every AIBOMs should have a DataBOMs", "D6": {"1": "4", "2": "2", "3": "1", "4": "3", "5": "5", "other": ""}, "D7": "It would help identify bias, vulnerability AI systems. \n\nIt would help in understanding how an Al system makes its predictions.", "D8": "Companies not willing to release some information particularly around data collection.\n\nThe potential threat of malicious actors using this information to find loop holes they can exploit.", "D9": "Having an independent community or board that checks."}, "challenges": {"C1": "This would help developers not involved in the project have a better understanding of the software they are working with. ", "C2": "Companies not willing to release information.\n\nMalicious actors taking advantage this information to find vulnerabilities ", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "All areas where data is sourced from should be included"}, "demographics": {"Q1": "2", "Q2": {"answers": "Other (please specify)", "other": "Data Engineer"}, "Q3": {"answers": "Bachelor's Degree", "other": ""}, "Q4": {"answers": ["Python", "Others (please specify)"], "other": "Scala"}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open and closed source", "Q7": "E commerce , financial services, insurance", "Q8": "No", "Q9": "No", "Q10": "Annually"}}, "5": {"meta": {"StartDate": "2023-03-02 10:38:25", "EndDate": "2023-03-02 10:49:53", "Status": "IP Address", "Progress": "100", "Duration": "688", "Finished": "True", "RecordedDate": "2023-03-02 10:49:55", "ResponseID": "R_3fqT2cEIFtvLSOn", "UserLanguage": "EN"}, "background": {"B1": "Yes", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "No", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Environment in which the model was trained in", "Model structure / architecture", "Model hyperparameters", "Potential fairness issues", "Optimizers, loss functions, etc.", "Description of the training data", "Description of the validation and testing data", "Data (pre-)processing techniques", "Presence of Personally Identifiable Information", "Model version", "Model description", "Model license", "Data version", "System dependencies"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "1", "2": "2", "3": "3", "4": "5", "5": "4", "6": "6", "other": ""}, "AI7": "Validation against third-party databases of possible dependencies, with the ability to add others not present in the registry only if users fill in structured data forms."}, "databom_fields": {"D1": "Agree", "D2": {"answers": "No", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Dataset authors / creators", "Procedure for data collection and curation", "Presence of Personally Identifiable Information", "Dataset version", "Dataset license", "Dataset description", "Creation time", "Known data biases", "Known vulnerabilities and issues", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "There should be unambiguous ways each can refer to the other.", "D6": {"1": "2", "2": "1", "3": "3", "4": "4", "5": "5", "other": ""}, "D7": "Easier to determine whether the data are appropriate for the application, and whether to suspect issues with studies/products that use those data. Ease of reproducibility.", "D8": "Terminologies and standards used to reduce ambiguity in the BOMs are probably lacking.", "D9": "Require validation of the BOM using a standardized validation tool upon submission to whatever system will store the data."}, "challenges": {"C1": "Unsure, not experienced enough with them.", "C2": "Unsure, not experienced enough with them.", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "I'm unsure due to lack of expertise in this area."}, "demographics": {"Q1": "6", "Q2": {"answers": "Other (please specify)", "other": "Assistant Professor"}, "Q3": {"answers": "Doctoral Degree", "other": ""}, "Q4": {"answers": ["Python", "C / C++", "Javascript"], "other": ""}, "Q5": {"answers": "Both deep and non-deep learning models", "other": ""}, "Q6": "Open and closed source", "Q7": "Healthcare, biomedicine", "Q8": "No", "Q9": "Yes, informal", "Q10": "Quarterly"}}, "6": {"meta": {"StartDate": "2023-03-02 12:38:46", "EndDate": "2023-03-02 14:09:37", "Status": "IP Address", "Progress": "100", "Duration": "5450", "Finished": "True", "RecordedDate": "2023-03-02 14:09:37", "ResponseID": "R_3DvvLm2ClM35LuV", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Environment in which the model was trained in", "Model structure / architecture", "Model hyperparameters", "Model parameters", "Potential model biases", "Potential fairness issues", "Unique model identifier", "Optimizers, loss functions, etc.", "Description of the validation and testing data", "Runtime performance requirements", "Model version", "Data version", "System dependencies"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "Yes (please list them)", "other": "Huggingface Hub, DVC, ML-Flow"}, "AI6": {"1": "4", "2": "1", "3": "2", "4": "5", "5": "3", "6": "6", "other": ""}, "AI7": "Ensure that both c++ and python dependencies are exactly pinned to the version used for training, (enforcing that inference code needs to be available already when training) and provide a docker container that has the full environment provided already (so devs can debug possible differences to updated dependencies [e.g. using pytorch 2.0 instead of 1.12]).\n\nEnsure that the model is created in a reproducible manner (e.g. trained on a fixed seed, while evaluating multiple training runs on different seeds)\n\nAdd easy support to domain drift detection, hence give the devs a possibility to quickly notice, if something went wrong in the data collection step and have the model exposed to data that is far away of the training data that is actually used."}, "databom_fields": {"D1": "Disagree", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Data labelers / taggers", "Procedure for data collection and curation", "Dataset version", "Dataset description", "Version description (dataset change log)", "Known data biases", "Known vulnerabilities and issues", "Unique identifier", "Dataset size"], "other": ""}, "D4": {"answers": "Yes (please list them)", "other": "Huggingface Datasets"}, "D5": "They should be well integrateable, showing cross dependencies whenever possible", "D6": {"1": "3", "2": "1", "3": "2", "4": "4", "5": "5", "other": ""}, "D7": "I would hope that DataBOMs include some kind of pre-data-analysis so I can get a good feeling of the data contained without having to inspect the data myself too much.\nBesides that, I want to be able to look up the exact versioning - being able to transform the data in different ways ", "D8": "Finding a good mix between accurate versioning and many updates. I would want to be able to access any version I trained a model with (or used some kind of data analysis on) but I would not like to have an updated version whenever I updated a single label (because then there would be thousands of versions if I update thousands of labels in a short time period).\n\nI also would like to be able to automatically check labeled data so I can inspect possible structural labeling errors as soon as possible (e.g. detect that something is marked as a date that is not parseable as a date, or having an invoice where the uid is not labeled).\nIn general I would expect any DataBOM being well integrated with a labeling tool - at best with several of the opensource labeling tools available - while not forcing to use exactly that tool.", "D9": "hashing the data so I can check for modifications, ensuring that the dataset is complete and contains the data fields mentioned above, "}, "challenges": {"C1": "Idealy I don't have to implement features like versioing manually myself, and even get inspired to use techniques that I usually don't think of myself (e.g. I would have never written code to monitor the GPU memory usage or GPU compute utility while training, even if I didn't have a tool that would monitor it for me.) and therefore ensure that I am using best practices or to be more concrete, my colleagues with lesser experience use best practices without me having to tell them everything :-)\n", "C2": "There needs to be some trade off between working out of the box and being customizable. For example at work we are currently using ClearML for training and monitoring, however ClearML's documentation is mostly \"you don't need to do anything, we do everything for you\", they are applying a lot of features we don't need/want while failing to do other things - like tracking metrics on a custom training loop - automatically. Then their documentation is not very good, as they expect their users to do the exact usecase they described, using certain training libraries. Making it more complicated to manually add metrics you want to add (although the solution was easy after knowing what the solution was)\nA good tool would make clear if it goes all in on acertain tool chain or - as I would prefer - make it easy to adapt it to any training I want, giving me options to adapt on several ways so I can choose the adoption that is the easiest for me.", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "I am not sure if they should, however I am also not deep in the copyright debate, as I usually use customer data I got permission to use."}, "demographics": {"Q1": "7", "Q2": {"answers": "ML/DL Engineer", "other": ""}, "Q3": {"answers": "Some college", "other": ""}, "Q4": {"answers": ["Python"], "other": ""}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open and closed source", "Q7": "B2B Projects in several domains including HealthCare, Finance, Tourism, Law/Public Services", "Q8": "Yes, formal", "Q9": "Yes, informal", "Q10": "Quarterly"}}, "7": {"meta": {"StartDate": "2023-03-02 15:00:39", "EndDate": "2023-03-02 15:13:37", "Status": "IP Address", "Progress": "100", "Duration": "777", "Finished": "True", "RecordedDate": "2023-03-02 15:13:37", "ResponseID": "R_2fQicKO6LMixLAR", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Environment in which the model was trained in", "Model parameters", "Description of the training data", "Description of the validation and testing data", "Runtime performance requirements", "Data (pre-)processing techniques", "Model version", "Model description", "Model license", "System dependencies"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "2", "2": "1", "3": "3", "4": "5", "5": "4", "6": "6", "other": ""}, "AI7": "CICD action that runs some tests"}, "databom_fields": {"D1": "Agree", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data pre-processing steps", "Data transformations", "Data labelers / taggers"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "If the first in present you should be able to get the second or a small portion of it, but not necessarily the other way around", "D6": {"1": "2", "2": "1", "3": "3", "4": "4", "5": "5", "other": ""}, "D7": "An example of \"usage\" for the model", "D8": "They're heavy and the distribution will be complicated because of it ", "D9": "Just using a CICD action that runs some tests "}, "challenges": {"C1": "An example of usage for the model...", "C2": "They're heavy so it will be complicated to deliver them...", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "We should always attach a license to insure if the author wants this he will be able to make the person using his data illegally to stop or get punished"}, "demographics": {"Q1": "1", "Q2": {"answers": "Programmer", "other": ""}, "Q3": {"answers": "Bachelor's Degree", "other": ""}, "Q4": {"answers": ["Python", "Java", "C / C++", "Javascript"], "other": ""}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open and closed source", "Q7": "Security ", "Q8": "Yes, informal", "Q9": "Yes, informal", "Q10": "Quarterly"}}, "8": {"meta": {"StartDate": "2023-03-02 16:43:15", "EndDate": "2023-03-02 16:50:58", "Status": "IP Address", "Progress": "100", "Duration": "463", "Finished": "True", "RecordedDate": "2023-03-02 16:50:58", "ResponseID": "R_2cAhImlk2Ck0mat", "UserLanguage": "EN"}, "background": {"B1": "Yes", "B2": {"answers": ["CycloneDX"], "other": ""}, "B3": {"answers": "No", "other": ""}}, "aibom_fields": {"AI1": "Neutral", "AI2": {"answers": ["Model hyperparameters", "Potential model biases"], "other": ""}, "AI3": "No, an entirely new solution is necessary", "AI4": "collect data such as the particular version of each component used", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "3", "2": "4", "3": "2", "4": "5", "5": "1", "6": "6", "other": ""}, "AI7": "Establishing clear rules and best practices for the development and deployment of ML/DL systems, including a defined procedure for building and upgrading AIBOMs, is one way."}, "databom_fields": {"D1": "Neutral", "D2": {"answers": "No", "other": ""}, "D3": {"answers": ["Data transformations", "Known data biases"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "The link between AIBOMs and DataBOMs (Data Bill of Materials) is critical for guaranteeing openness and accountability in ML/DL system development and deployment.", "D6": {"1": "1", "2": "4", "3": "3", "4": "2", "5": "5", "other": ""}, "D7": "Quality Control", "D8": "Maintenance", "D9": " Data Governance"}, "challenges": {"C1": "Reproducibility", "C2": "Standardization", "C3": {"answers": "No", "other": ""}, "C4": "", "C5": {"answers": "No", "other": ""}, "C6": "", "C7": "Getting the copyright holder's approval or using open-source software"}, "demographics": {"Q1": "9", "Q2": {"answers": "Programmer", "other": ""}, "Q3": {"answers": "Master's Degree", "other": ""}, "Q4": {"answers": ["Python"], "other": ""}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open and closed source", "Q7": "telecom", "Q8": "Yes, formal", "Q9": "Yes, informal", "Q10": "Quarterly"}}, "9": {"meta": {"StartDate": "2023-03-02 21:37:43", "EndDate": "2023-03-02 22:17:42", "Status": "IP Address", "Progress": "100", "Duration": "2398", "Finished": "True", "RecordedDate": "2023-03-02 22:17:43", "ResponseID": "R_Wx2cn6RfYxDu3Dz", "UserLanguage": "EN"}, "background": {"B1": "Yes", "B2": {"answers": ["SPDX", "CycloneDX"], "other": ""}, "B3": {"answers": "No", "other": ""}}, "aibom_fields": {"AI1": "Agree", "AI2": {"answers": ["Known model/data defects", "Potential model biases", "Description of the training data", "Runtime performance requirements", "Model version", "Model description", "Creation / building time", "Model license", "Data version", "System dependencies"], "other": ""}, "AI3": "Yes, current SBOMs can be adapted to support AI systems", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "6": "6", "other": ""}, "AI7": "Reproducable results from a trusted third party.\nValidation with trusted datasets.\nCertified vendor."}, "databom_fields": {"D1": "Neutral", "D2": {"answers": "No", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Dataset authors / creators", "Data labelers / taggers", "Presence of Personally Identifiable Information", "Dataset version", "Dataset license", "Dataset description", "Creation time", "Known data biases", "Known vulnerabilities and issues", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size", "Others (please specify)"], "other": "Train/Test/Val split\n"}, "D4": {"answers": "No", "other": ""}, "D5": "Aibom should have a reference to at least a validation dataset and probably performance metrics with it", "D6": {"1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "other": ""}, "D7": "Model validation and testing. Comparing production environment metrics with Author's results.", "D8": "Data privacy and security. ", "D9": "Reproducing results by trusted third party. That can be partial, like validation data only."}, "challenges": {"C1": "Reducing security risks.\nMaking deployment/updates faster.", "C2": "Training dataset is usually large and top secret of a company. It's hard to involve some third party here. Solving that may require some new laws.", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "If such data is used, the methodology should be described. Would be also nice to have some proof-of-legal-use document included."}, "demographics": {"Q1": "10", "Q2": {"answers": "ML/DL Engineer", "other": ""}, "Q3": {"answers": "Master's Degree", "other": ""}, "Q4": {"answers": ["Python", "Java", "C / C++", "Javascript", "Others (please specify)"], "other": "Rust, Bash, Typescript, Assembler"}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Closed source only", "Q7": "Manufacturing, Airspace, Defense, Police", "Q8": "Yes, informal", "Q9": "Yes, informal", "Q10": "More frequently"}}, "10": {"meta": {"StartDate": "2023-03-03 07:38:42", "EndDate": "2023-03-03 07:56:40", "Status": "IP Address", "Progress": "100", "Duration": "1078", "Finished": "True", "RecordedDate": "2023-03-03 07:56:40", "ResponseID": "R_2Y5O7bIDKYRDgxj", "UserLanguage": "EN"}, "background": {"B1": "Yes", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "No", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Environment in which the model was trained in", "Model structure / architecture", "Model hyperparameters", "Model parameters", "Known model/data defects", "Unique model identifier", "Optimizers, loss functions, etc.", "Description of the training data", "Description of the validation and testing data", "Data (pre-)processing techniques"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "2", "2": "1", "3": "3", "4": "4", "5": "5", "6": "6", "other": ""}, "AI7": "Often it is as simple as providing the model code along with a requirements.txt file to specify dependencies.  Data must be provided in the same format as given to the model for training, and also in raw format where possible.  However, privacy concerns could trump reproducibility concerns at times."}, "databom_fields": {"D1": "Neutral", "D2": {"answers": "No", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Presence of Personally Identifiable Information", "Dataset statistics", "Dataset description", "Known vulnerabilities and issues", "Unique identifier", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "I see them as independent.  An AIBOM should refer to a DataBOM where applicable.", "D6": {"1": "2", "2": "1", "3": "3", "4": "4", "5": "5", "other": ""}, "D7": "Benefits include better ability to detect biases and increased reproducibility of results.", "D8": "A major risk is that the BOM becomes \"yet another\" bureaucratic nightmare involving more and more documents to fill out, without actually solving the underlying problem.", "D9": "Cryptographic hash functions of the data can help ensure that the version is in fact what they say it is."}, "challenges": {"C1": "As with DataBOMs, one big benefit is the ability to better detect biases and reproduce results.", "C2": "Also as with DataBOMs, a major risk is that it increases paperwork without actually solving the underlying problem.  Requiring AIBOMs could create a quagmire of red tape.", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "I've brought up this issue for years, but no one has ever wanted to discuss it.  Terms of Service and licenses can forbid the practice, but it happens anyway.  In theory, an AIBOM could require builders of AI systems to disclose that a system was trained using licensed data, but I suspect there would be rampant violation of the requirement.  No one wants to admit that their new AI system works well because it copies creative effort."}, "demographics": {"Q1": "6", "Q2": {"answers": "Project Lead", "other": ""}, "Q3": {"answers": "Doctoral Degree", "other": ""}, "Q4": {"answers": ["Python", "Java", "C / C++"], "other": ""}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open source only", "Q7": "Academic", "Q8": "Yes, informal", "Q9": "Yes, informal", "Q10": "Quarterly"}}, "11": {"meta": {"StartDate": "2023-03-04 17:12:52", "EndDate": "2023-03-04 17:34:00", "Status": "IP Address", "Progress": "100", "Duration": "1267", "Finished": "True", "RecordedDate": "2023-03-04 17:34:00", "ResponseID": "R_1q8n5SpYhsIYMg4", "UserLanguage": "EN"}, "background": {"B1": "Yes", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "No", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Model parameters", "Known model/data defects", "Potential model biases", "Potential fairness issues", "Description of the training data"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "3", "2": "1", "3": "2", "4": "5", "5": "4", "6": "6", "other": ""}, "AI7": "Apart from software packages, dependencies of ML/DL systems include training/testing data which essentially defines the algorithm. I would emphasize on the reporting on the data dependencies. "}, "databom_fields": {"D1": "Agree", "D2": {"answers": "No", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data labelers / taggers", "Procedure for data collection and curation", "Creation time", "Known data biases", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "Not sure. ", "D6": {"1": "3", "2": "1", "3": "2", "4": "4", "5": "5", "other": ""}, "D7": "Some kind of guarantees of the model performance. ", "D8": "The license, GDPR, uncertainty factors, etc. ", "D9": "Documentation, rigourous testing, formalization. "}, "challenges": {"C1": "The secure and safe usage in critical domains. ", "C2": "Common standard, diverse use cases, confidentiality of data. ", "C3": {"answers": "No", "other": ""}, "C4": "", "C5": {"answers": "No", "other": ""}, "C6": "", "C7": "Not sure. "}, "demographics": {"Q1": "6", "Q2": {"answers": "Other (please specify)", "other": "ML/DL Researcher "}, "Q3": {"answers": "Doctoral Degree", "other": ""}, "Q4": {"answers": ["Python"], "other": ""}, "Q5": {"answers": "Both deep and non-deep learning models", "other": ""}, "Q6": "Open and closed source", "Q7": "Healthcare, Finance.", "Q8": "Yes, formal", "Q9": "No", "Q10": "Annually"}}, "12": {"meta": {"StartDate": "2023-03-04 18:38:24", "EndDate": "2023-03-04 19:24:39", "Status": "IP Address", "Progress": "100", "Duration": "2775", "Finished": "True", "RecordedDate": "2023-03-04 19:24:40", "ResponseID": "R_1mmIXtQKGgLWU7P", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Unique model identifier", "Description of the training data", "Model version", "Creation / building time", "System dependencies"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "5", "2": "1", "3": "3", "4": "4", "5": "2", "6": "6", "other": ""}, "AI7": "Ensure model runs in a well-defined environment using tools such as Anaconda to automatically define exact package version dependencies.\n\nInformation about the training dataset should be kept track of somehow, though it's unclear to me how that could be done. Something similar to Huggingface Datasets that keeps track of the data itself as well as its provenance information (source, retrieval date, etc)."}, "databom_fields": {"D1": "Agree", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Procedure for data collection and curation", "Dataset version", "Unique identifier", "Dataset size"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "AIBOM should point to one or more DataBOM that describe the training data used to create the model.", "D6": {"1": "3", "2": "1", "3": "2", "4": "4", "5": "5", "other": ""}, "D7": "If a widespread dataset poisoning attack was ever actually performed, it would be easier to figure out which models are affected.", "D8": "It seems like DataBOMs would only be possible by using some central tool that manages all data fed into a model so that ad-hoc data (for example, from other files on disk) isn't trained into the model without being tracked.", "D9": "Somebody would have to design a 'canonical' training procedure that defines a process for generating approved dataset files that get read and verified somehow during the training process to make sure no unknown/outside data is used to train a model"}, "challenges": {"C1": "People using models would be able to more easily discover issues with the models they're using.", "C2": "If creation of an AIBOM requires manual effort on the part of the people creating the model, it's likely not going to be widely adopted. It may be difficult to adopt any new process if it adds significant friction between the action of retrieving data and using it in training the model.", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "If using external copyrighted data, the Data BOM should include the URL the data was scraped from and timestamp of when the data was scraped.\n\nIn an ideal world, there would be some system copyright owners could use to determine if their copyrighted data was included in the dataset. If so, they should be entitled to know what portion of their copyrighted data was used (i.e. they should be able to see and download 'their' data from the training dataset)."}, "demographics": {"Q1": "0", "Q2": {"answers": "Other (please specify)", "other": "independent hobbyist ai researcher"}, "Q3": {"answers": "Bachelor's Degree", "other": ""}, "Q4": {"answers": ["Python", "C / C++", "C#"], "other": ""}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open and closed source", "Q7": "N/A", "Q8": "No", "Q9": "No", "Q10": "Quarterly"}}, "13": {"meta": {"StartDate": "2023-03-05 09:12:25", "EndDate": "2023-03-05 09:41:57", "Status": "IP Address", "Progress": "100", "Duration": "1772", "Finished": "True", "RecordedDate": "2023-03-05 09:41:58", "ResponseID": "R_55W4oRWHfxOQzT3", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Environment in which the model was trained in", "Model structure / architecture", "Potential model biases", "Potential fairness issues", "Unique model identifier", "Description of the training data", "Description of the validation and testing data", "Runtime performance requirements", "Data (pre-)processing techniques", "Presence of Personally Identifiable Information", "Model description", "Model license", "Data version", "System dependencies"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "Yes (please list them)", "other": "huggingface model card/dataset card"}, "AI6": {"1": "3", "2": "2", "3": "4", "4": "5", "5": "1", "6": "6", "other": ""}, "AI7": "1. Trusted 3rd party verification\n2. Users/developers report false or incorrect dependencies"}, "databom_fields": {"D1": "Strongly agree", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Dataset authors / creators", "Procedure for data collection and curation", "Presence of Personally Identifiable Information", "Dataset statistics", "Dataset version", "Dataset license", "Dataset description", "Version description (dataset change log)", "Creation time", "Known data biases", "Known vulnerabilities and issues", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "DataBOMs should be the base of AIBOMs, as how different datasets are processed, curated, and labeled largely affect the performance and usability of the ML/DL system. Misuse of data could lead to harmful consequences, including hate responses, privacy leaks, and infringement of IP and copyrights.", "D6": {"1": "2", "2": "1", "3": "3", "4": "4", "5": "5", "other": ""}, "D7": "1. Prevent abuse of the dataset\n2. Help to protect the IP both the source of the raw data and the processed dataset", "D8": "1. Hard to define fields for describing different data in a standard way\n2. Hard to verify the effectiveness of the data", "D9": "I am not sure about this part, traditional data quality may help to ensure components of the dataset partially."}, "challenges": {"C1": "Mostly the same as the DataBOM, it helps to verify the usability of the AIBOMs and helps to identify the potential issues and risks.", "C2": "Hard to verify the correctness of the claimed dependencies, especially for big models. With more common AI services like OpenAI APIs provided as a part of software development, many of these services are hidden, and difficult for the public to check their risks and issues. Even its users and developers hardly understand what will be the data and ML process it will invoke.", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "1. The presence of licensed material, and what licenses\n2. Will this be a conflict of interest and infringement of copyrights to the original licensed material?\n3. If these materials are processed, will the personal information/identification (e.g., human face, drawing style) be able to be retrieved and recognized?"}, "demographics": {"Q1": "3", "Q2": {"answers": "ML/DL Engineer", "other": ""}, "Q3": {"answers": "Bachelor's Degree", "other": ""}, "Q4": {"answers": ["Python"], "other": ""}, "Q5": {"answers": "Both deep and non-deep learning models", "other": ""}, "Q6": "Open and closed source", "Q7": "e-commerce", "Q8": "Yes, formal", "Q9": "No", "Q10": "Quarterly"}}, "14": {"meta": {"StartDate": "2023-03-05 20:27:31", "EndDate": "2023-03-05 20:36:58", "Status": "IP Address", "Progress": "100", "Duration": "567", "Finished": "True", "RecordedDate": "2023-03-05 20:36:59", "ResponseID": "R_4NF31pzBLP32S6R", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Model structure / architecture", "Model hyperparameters", "Model parameters", "Known model/data defects", "Unique model identifier", "Optimizers, loss functions, etc.", "Description of the training data", "Description of the validation and testing data", "Data (pre-)processing techniques", "Presence of Personally Identifiable Information", "Model version", "Model description", "Model license", "Data version", "System dependencies"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "1", "2": "3", "3": "2", "4": "4", "5": "5", "6": "6", "other": ""}, "AI7": "Provenance information"}, "databom_fields": {"D1": "Agree", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Dataset authors / creators", "Data labelers / taggers", "Procedure for data collection and curation", "Presence of Personally Identifiable Information", "Dataset statistics", "Dataset version", "Dataset license", "Dataset description", "Version description (dataset change log)", "Creation time", "Known data biases", "Known vulnerabilities and issues", "Unique identifier", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "Downstream and upstream", "D6": {"1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "other": ""}, "D7": "Solving data poisoning issues, reproducibility issues", "D8": "Size and versioning", "D9": "Again, provenance"}, "challenges": {"C1": "Trustworthy -- against supply chain type of attacks", "C2": "Size, versioning", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "Follow the license requirement. But I also think some license needs updates."}, "demographics": {"Q1": "7", "Q2": {"answers": "Data scientist", "other": ""}, "Q3": {"answers": "Doctoral Degree", "other": ""}, "Q4": {"answers": ["Python", "Java"], "other": ""}, "Q5": {"answers": "Both deep and non-deep learning models", "other": ""}, "Q6": "Open and closed source", "Q7": "N/A", "Q8": "Yes, formal", "Q9": "Yes, formal", "Q10": "Annually"}}, "15": {"meta": {"StartDate": "2023-03-06 02:38:36", "EndDate": "2023-03-06 03:05:49", "Status": "IP Address", "Progress": "100", "Duration": "1632", "Finished": "True", "RecordedDate": "2023-03-06 03:05:49", "ResponseID": "R_pRGaZXs482rgAZX", "UserLanguage": "EN"}, "background": {"B1": "Yes", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "No", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Environment in which the model was trained in", "Model structure / architecture", "Model hyperparameters", "Model parameters", "Unique model identifier", "Optimizers, loss functions, etc.", "Description of the training data", "Description of the validation and testing data", "Data (pre-)processing techniques", "Presence of Personally Identifiable Information", "Model version", "Model description", "Creation / building time", "Model license", "Data version", "System dependencies"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "4", "2": "1", "3": "3", "4": "5", "5": "2", "6": "6", "other": ""}, "AI7": "Not sure if there is a way, at the moment. An automated tool for checking that what is reported in the AIBOM is correct and complete would be useful. I do not know to what extent that would be feasible, though."}, "databom_fields": {"D1": "Neutral", "D2": {"answers": "No", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Dataset authors / creators", "Procedure for data collection and curation", "Presence of Personally Identifiable Information", "Dataset version", "Dataset license", "Dataset description", "Creation time", "Known data biases", "Known vulnerabilities and issues", "Unique identifier", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "They should be provided together; having only one of them would be useless. ", "D6": {"1": "3", "2": "1", "3": "2", "4": "4", "5": "5", "other": ""}, "D7": "It would help increase the trust in the model.", "D8": "The main challenges regard sensitive, personally identifiable, and private information, in general. Having a comprehensive DataBOM when such data are involved might be infeasible for privacy reasons. As an alternative, it might be necessary to provide a lower quantity of information (even aggregated).", "D9": "Not sure this is feasible when private information used."}, "challenges": {"C1": "As for the DataBOM, it would help increase the trust in the model.", "C2": "No particular challenge.", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "It should explicitly report the licenses of the used material, when relevant."}, "demographics": {"Q1": "3", "Q2": {"answers": "Other (please specify)", "other": "Researcher"}, "Q3": {"answers": "Doctoral Degree", "other": ""}, "Q4": {"answers": ["Python", "Java"], "other": ""}, "Q5": {"answers": "Non-deep learning models (SVMs, Decision Trees, etc.)", "other": ""}, "Q6": "Open and closed source", "Q7": "Software Engineering research; Healthcare", "Q8": "Yes, informal", "Q9": "Yes, informal", "Q10": "Annually"}}, "16": {"meta": {"StartDate": "2023-03-08 19:25:09", "EndDate": "2023-03-08 19:36:33", "Status": "IP Address", "Progress": "100", "Duration": "683", "Finished": "True", "RecordedDate": "2023-03-08 19:36:33", "ResponseID": "R_1mnnusK22udQw8S", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Model structure / architecture", "Model hyperparameters", "Model parameters", "Potential model biases", "Unique model identifier", "Optimizers, loss functions, etc.", "Description of the training data", "Description of the validation and testing data", "Runtime performance requirements", "Model version", "Model description", "Model license", "Data version", "System dependencies", "Others (please specify)"], "other": "Programming Language and libraries to use for implementation,\nOther users and their experiences if any available, and cost of running the model and the inference per image/input."}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "4", "2": "2", "3": "1", "4": "3", "5": "5", "6": "6", "other": ""}, "AI7": "Universal API can provide this information. "}, "databom_fields": {"D1": "Strongly agree", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Dataset authors / creators", "Data labelers / taggers", "Procedure for data collection and curation", "Dataset statistics", "Dataset version", "Dataset license", "Dataset description", "Version description (dataset change log)", "Creation time", "Known data biases", "Known vulnerabilities and issues", "Unique identifier", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size", "Others (please specify)"], "other": "individual image usage history. If an image is used in another dataset, it would be great to mention this on data changelog."}, "D4": {"answers": "No", "other": ""}, "D5": "Support each other for a better training experience", "D6": {"1": "3", "2": "2", "3": "1", "4": "4", "5": "5", "other": ""}, "D7": "I don't know.", "D8": "There should be a mechanism to carry and show image hash with each image. Sometimes, images may seem that they are exactly the same but their hash values are different.", "D9": "I don't know."}, "challenges": {"C1": "No comment", "C2": "Some may see as not needed information.", "C3": {"answers": "No", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "Can be a part of an image like PPM"}, "demographics": {"Q1": "10", "Q2": {"answers": "ML/DL Engineer", "other": ""}, "Q3": {"answers": "Other (please specify)", "other": "PhD candidate, and still purseuing"}, "Q4": {"answers": ["Python"], "other": ""}, "Q5": {"answers": "Both deep and non-deep learning models", "other": ""}, "Q6": "Open and closed source", "Q7": "Retail, logistics, marketing, banking, healthcare, medical imaging, defense, security, and disease monitoring and diagnostics.", "Q8": "No", "Q9": "No", "Q10": "Monthly"}}, "17": {"meta": {"StartDate": "2023-03-07 13:36:16", "EndDate": "2023-03-09 19:33:56", "Status": "IP Address", "Progress": "100", "Duration": "194259", "Finished": "True", "RecordedDate": "2023-03-09 19:33:56", "ResponseID": "R_1n7Jt1YCHoTG4OD", "UserLanguage": "EN"}, "background": {"B1": "Yes", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "No", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Environment in which the model was trained in", "Model hyperparameters", "Unique model identifier", "Description of the training data", "Description of the validation and testing data", "Data (pre-)processing techniques", "Model version", "Data version"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "1", "2": "3", "3": "4", "4": "5", "5": "2", "6": "6", "other": ""}, "AI7": "If the goal is full reproducibility, it is an open problem. If we settle for accountability and tracking for the purpose of security updates, I think it's do-able using existing \"enumerate the libraries\"-type approaches."}, "databom_fields": {"D1": "Strongly agree", "D2": {"answers": "No", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Dataset version", "Unique identifier"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "DataBOMs are a subset of AIBOMs. Any ML/AI model shipped with an AIBMO was trained on data that is described with a DataBOM.", "D6": {"1": "1", "2": "2", "3": "3", "4": "4", "5": "5", "other": ""}, "D7": "Better sense of the biases in datasets", "D8": "Many datasets are labeled by volunteers or untrusted folks (e.g. Amazon Mechanical Turk) and it is hard to formally represent those characteristics or interpret them.", "D9": "I guess if you are using ML for data labeling, you could make some progress. With human annotation it seems impossible to fully characterize."}, "challenges": {"C1": "Might help with the so-called \"reproducibility crisis\" in AI, though frankly I'm skeptical. I think the bigger benefit would be a CVE-like reporting of bias in datasets that let us see which models should be updated.", "C2": "We barely use SBOMs, and AIBOMs will be harder.", "C3": {"answers": "Yes (please list them)", "other": "The CVE database...?"}, "C4": "Neutral", "C5": {"answers": "Yes (please list them)", "other": "The CVE database?"}, "C6": "Neutral", "C7": "The creators of datasets are responsible for honoring licenses. Governments should introduce legislation and/or regulation to enforce this -- GDPR etc."}, "demographics": {"Q1": "3", "Q2": {"answers": "Other (please specify)", "other": "Professor"}, "Q3": {"answers": "Doctoral Degree", "other": ""}, "Q4": {"answers": ["Python", "Java", "C / C++", "Javascript"], "other": ""}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open source only", "Q7": "Academic", "Q8": "Yes, formal", "Q9": "Yes, informal", "Q10": "Never"}}, "18": {"meta": {"StartDate": "2023-03-10 02:07:16", "EndDate": "2023-03-10 02:21:49", "Status": "IP Address", "Progress": "100", "Duration": "872", "Finished": "True", "RecordedDate": "2023-03-10 02:21:50", "ResponseID": "R_Z9OwHebnJViKb05", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Model structure / architecture", "Model parameters", "Optimizers, loss functions, etc.", "System dependencies"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "4", "2": "6", "3": "2", "4": "3", "5": "1", "6": "5", "other": ""}, "AI7": "A module in the AIBOM should compare the ML model with the dependencies specified in the AIBOM.\n\nOR\n\nThe ML model is trained via the AIBOM and therefore a mistake in the AIBOM would not allow the model to be used and vice-versa.\n"}, "databom_fields": {"D1": "Strongly agree", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data sources", "Data transformations", "Dataset authors / creators", "Procedure for data collection and curation", "Version description (dataset change log)", "Known data biases", "Known vulnerabilities and issues", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "DataBOMs should be a part/section of AIBOMs", "D6": {"1": "4", "2": "1", "3": "2", "4": "3", "5": "5", "other": ""}, "D7": "Idendity with more ease biases that could emerge from the data\nBetter classify the data", "D8": "The maintenance of keeping them up-to-date.", "D9": "I am not sure."}, "challenges": {"C1": "Continous Integration of AI models", "C2": "Making them work on many different AI models/systems.", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "They should identify and group the licenses, and report them to the developer so that he or she can exclude the data or contact the person owning the license"}, "demographics": {"Q1": "2", "Q2": {"answers": "Programmer", "other": ""}, "Q3": {"answers": "Bachelor's Degree", "other": ""}, "Q4": {"answers": ["Python", "C#"], "other": ""}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open and closed source", "Q7": "audio processing", "Q8": "No", "Q9": "No", "Q10": "Monthly"}}, "19": {"meta": {"StartDate": "2023-03-17 16:32:12", "EndDate": "2023-03-17 16:58:35", "Status": "IP Address", "Progress": "100", "Duration": "1583", "Finished": "True", "RecordedDate": "2023-03-17 16:58:36", "ResponseID": "R_1re29t5ffAzofYC", "UserLanguage": "EN"}, "background": {"B1": "No", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Environment in which the model was trained in", "Model structure / architecture", "Model hyperparameters", "Model parameters", "Known model/data defects", "Potential model biases", "Potential fairness issues", "Optimizers, loss functions, etc.", "Description of the training data", "Description of the validation and testing data", "Runtime performance requirements", "Data (pre-)processing techniques", "Presence of Personally Identifiable Information", "Model version", "Model description", "Model license", "Data version", "System dependencies"], "other": ""}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "2", "2": "1", "3": "3", "4": "5", "5": "4", "6": "6", "other": ""}, "AI7": "Maybe a screening pipeline that validates and provide some certificates on the validity and requirements of AIBOMs "}, "databom_fields": {"D1": "Agree", "D2": {"answers": "", "other": ""}, "D3": {"answers": ["Data sources", "Data pre-processing steps", "Data transformations", "Dataset authors / creators", "Procedure for data collection and curation", "Presence of Personally Identifiable Information", "Dataset statistics", "Dataset version", "Dataset license", "Dataset description", "Version description (dataset change log)", "Creation time", "Known data biases", "Known vulnerabilities and issues", "Unique identifier", "Types of data included in the dataset (image, text, binary, etc)", "Dataset size"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "Certify whether a specific AIBOM is compatible and operational on a DataBOM", "D6": {"1": "2", "2": "1", "3": "3", "4": "4", "5": "5", "other": ""}, "D7": "Better traceability, versioning, reproducibility of studies", "D8": "Standardizing the format and the adoption", "D9": "Create automated tools that support the validation, standardization, upgrade, and audit of the DataBOMs."}, "challenges": {"C1": "Similarly to dataBOMs, it could help with reproducing studies, better collaboration, faster iteration and improvements of model. Bugs, biases, and fairness issues could be discovered quickly", "C2": "Adoption of these systems by large organizations. The continuous evolution and changes in the models could make them obsolete quite quickly. ", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "Automate the screening process and report warnings about possible license infringement"}, "demographics": {"Q1": "6", "Q2": {"answers": "Data scientist", "other": ""}, "Q3": {"answers": "Doctoral Degree", "other": ""}, "Q4": {"answers": ["Python", "Java"], "other": ""}, "Q5": {"answers": "Deep Learning models (CNNs, RNNs, Transformers, etc.)", "other": ""}, "Q6": "Open and closed source", "Q7": "Software Engineering, development", "Q8": "No", "Q9": "No", "Q10": "Annually"}}, "20": {"meta": {"StartDate": "2023-03-19 09:57:22", "EndDate": "2023-03-19 17:55:54", "Status": "IP Address", "Progress": "100", "Duration": "28712", "Finished": "True", "RecordedDate": "2023-03-19 17:55:55", "ResponseID": "R_37tJ6C11CZ9OlfH", "UserLanguage": "EN"}, "background": {"B1": "Yes", "B2": {"answers": [""], "other": ""}, "B3": {"answers": "No", "other": ""}}, "aibom_fields": {"AI1": "", "AI2": {"answers": ["Model structure / architecture", "Optimizers, loss functions, etc.", "Description of the training data", "Description of the validation and testing data", "Data (pre-)processing techniques", "Model version", "Model description", "Data version", "System dependencies", "Others (please specify)"], "other": "'- Description of the intended (model) use\n- Model initialization techniques"}, "AI3": "", "AI4": "", "AI5": {"answers": "No", "other": ""}, "AI6": {"1": "6", "2": "1", "3": "2", "4": "5", "5": "3", "6": "4", "other": ""}, "AI7": "'- Trust\n- Clever application of zero-knowledge proofs\n- Build data integrity with what Christian Catalini calls \"costless verification\""}, "databom_fields": {"D1": "Strongly agree", "D2": {"answers": "No", "other": ""}, "D3": {"answers": ["Data sources", "Data transformations", "Procedure for data collection and curation", "Dataset version", "Dataset description", "Dataset size"], "other": ""}, "D4": {"answers": "No", "other": ""}, "D5": "AIBOMs should contain DataBOMs", "D6": {"1": "5", "2": "1", "3": "2", "4": "4", "5": "3", "other": ""}, "D7": "First and foremost, help manage compliance risk", "D8": "'- Documenting sources and methods\n- Maintaining sources and methods\n- Synthesizing descriptions\n- Maintaining descriptions", "D9": "'- Trust\n- Clever application of zero-knowledge proofs\n- Build data integrity with what Christian Catalini calls \"costless verification\""}, "challenges": {"C1": "First and foremost, help manage compliance risk", "C2": "'- Documenting methods\n- Maintaining methods\n- Synthesizing descriptions\n- Maintaining descriptions", "C3": {"answers": "I don't know", "other": ""}, "C4": "", "C5": {"answers": "", "other": ""}, "C6": "", "C7": "I think this question is too broad :)"}, "demographics": {"Q1": "14", "Q2": {"answers": "Other (please specify)", "other": "Director"}, "Q3": {"answers": "Doctoral Degree", "other": ""}, "Q4": {"answers": ["Python", "Java", "C#"], "other": ""}, "Q5": {"answers": "Both deep and non-deep learning models", "other": ""}, "Q6": "Closed source only", "Q7": "Department of Defense, Healthcare", "Q8": "No", "Q9": "No", "Q10": "Quarterly"}}}