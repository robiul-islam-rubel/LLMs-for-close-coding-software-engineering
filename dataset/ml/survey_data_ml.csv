survey_response,human_codes
"I think that a push and shift toward increased documentation and the use of AIBOMs, or at least some of their components, will help report dependencies. This can be seen in the past  or so years, where there is a large increase of paper authors publishing code and including a list of hyperparameters, training recipes, software package versions, hardware used, and other details about experiments in papers. I think that as top venues start to require more of these documentations, there will be a shift to where publishing AIBOMs becomes the norm.","['IncreasedAdoption', 'Documentation', 'Requirements']"
I can only think of being able to reproduce the model to be completely sure of how it was created.,['ReproduceModel']
Should contain virtually everything mentioned in the last question. Even then reproducing results could be tricky.,['BadAnswer']
"Having a sort of certification board or community, where open source AI software submit their projects for rd party assessment.",['Certification']
"Validation against thirdparty databases of possible dependencies, with the ability to add others not present in the registry only if users fill in structured data forms.",['Databases']
"Ensure that both c++ and python dependencies are exactly pinned to the version used for training, (enforcing that inference code needs to be available already when training) and provide a docker container that has the full environment provided already (so devs can debug possible differences to updated dependencies [e.g. using pytorch . instead of .]).Ensure that the model is created in a reproducible manner (e.g. trained on a fixed seed, while evaluating multiple training runs on different seeds)Add easy support to domain drift detection, hence give the devs a possibility to quickly notice, if something went wrong in the data collection step and have the model exposed to data that is far away of the training data that is actually used.","['PinnedVersions', 'IncludedEnvironment', 'ReproduceModel']"
CICD action that runs some tests,['ContinuousIntegrationTests']
"Establishing clear rules and best practices for the development and deployment of ML/DL systems, including a defined procedure for building and upgrading AIBOMs, is one way.",['EstablishBestPractices']
Reproducable results from a trusted third party.Validation with trusted datasets.Certified vendor.,"['Certification', 'ReproduceModel']"
"Often it is as simple as providing the model code along with a requirements.txt file to specify dependencies.  Data must be provided in the same format as given to the model for training, and also in raw format where possible.  However, privacy concerns could trump reproducibility concerns at times.","['ModelCode', 'ListLibraries', 'ReproduceModel']"
"Apart from software packages, dependencies of ML/DL systems include training/testing data which essentially defines the algorithm. I would emphasize on the reporting on the data dependencies. ",['EmphasisOnDataDependencies']
"Ensure model runs in a welldefined environment using tools such as Anaconda to automatically define exact package version dependencies.Information about the training dataset should be kept track of somehow, though its unclear to me how that could be done. Something similar to Huggingface Datasets that keeps track of the data itself as well as its provenance information (source, retrieval date, etc).",['EmphasisOnDataDependencies']
. Trusted rd party verification. Users/developers report false or incorrect dependencies,"['CommunityReporting', 'Certification']"
Provenance information,['ProvenanceInformation']
"Not sure if there is a way, at the moment. An automated tool for checking that what is reported in the AIBOM is correct and complete would be useful. I do not know to what extent that would be feasible, though.",['AutomatedTool']
Universal API can provide this information.,['UniversalAPI']
"If the goal is full reproducibility, it is an open problem. If we settle for accountability and tracking for the purpose of security updates, I think its doable using existing enumerate the librariestype approaches.",['ListLibraries']
A module in the AIBOM should compare the ML model with the dependencies specified in the AIBOM.ORThe ML model is trained via the AIBOM and therefore a mistake in the AIBOM would not allow the model to be used and viceversa.,"['ModelCode', 'ModelTrainedViaAIBOM', 'ListLibraries']"
Maybe a screening pipeline that validates and provide some certificates on the validity and requirements of AIBOMs,['ScreeningPipeline']
Trust Clever application of zeroknowledge proofs Build data integrity with what Christian Catalini calls costless verification,"['ZeroKnowledgeProof', 'CostlessVerification']"
"If you are proposing a dataset, make a dataBOM along with it. if you are using data, link to the dataset using a resource that also has the dataBOM accessible. If you are doing any sort of training in the process of working with data, create an AIBOM describing this training. I think that they should be separate overall, with each serving to describe a different category of things.",['Separate']
The data is what defines what the model will learn. So knowing about the data half the story of a model.,['BadAnswer']
"You would need both to reproduce results from an ML system, so they should be considered complementary.","['Separate', 'Complementary']"
Every AIBOMs should have a DataBOMs,['BadAnswer']
There should be unambiguous ways each can refer to the other.,"['References', 'Separate']"
"They should be well integrateable, showing cross dependencies whenever possible",['Integratable']
"If the first in present you should be able to get the second or a small portion of it, but not necessarily the other way around",['NonSymmetric']
The link between AIBOMs and DataBOMs (Data Bill of Materials) is critical for guaranteeing openness and accountability in ML/DL system development and deployment.,['BadAnswer']
Aibom should have a reference to at least a validation dataset and probably performance metrics with it,"['References', 'Separate']"
I see them as independent.  An AIBOM should refer to a DataBOM where applicable.,"['Complementary', 'NonSymmetric', 'References', 'Separate']"
Not sure.,['Unsure']
AIBOM should point to one or more DataBOM that describe the training data used to create the model.,"['OneToMany', 'References', 'Separate', 'NonSymmetric', 'Complementary']"
"DataBOMs should be the base of AIBOMs, as how different datasets are processed, curated, and labeled largely affect the performance and usability of the ML/DL system. Misuse of data could lead to harmful consequences, including hate responses, privacy leaks, and infringement of IP and copyrights.",['Base']
Downstream and upstream,"['DataFromUpstream', 'AiForDownstream']"
They should be provided together; having only one of them would be useless.,"['Separate', 'PackagedTogether']"
Support each other for a better training experience,"['Complementary', 'Separate']"
DataBOMs are a subset of AIBOMs. Any ML/AI model shipped with an AIBMO was trained on data that is described with a DataBOM.,['Complementary']
DataBOMs should be a part/section of AIBOMs,['DataBomPartOfAibom']
Certify whether a specific AIBOM is compatible and operational on a DataBOM,"['Compatible', 'Separate']"
AIBOMs should contain DataBOMs,['DataBomPartOfAibom']
"Sample code will make data easier to work with, as will hosting. I should not have to go a scrape a dataset using a csv of flickr URLs.",['EasierToWorkWith']
I think people already try to document their datasets. having a structure will help them to not forget to detail specific aspects of the dataset. Like Nature Scientific Data provides a structure that is very useful.,['BetterDocumentation']
Often data preprocessing steps that are critical for good performance / reproduction of results go unmentioned in papers. A DataBOM could help make these more transparent.,"['Reproducibility', 'IncreasedTransparency']"
"It would help identify bias, vulnerability AI systems. It would help in understanding how an Al system makes its predictions.","['IdentifyVulnerabilities', 'IncreasedModelUnderstanding']"
"Easier to determine whether the data are appropriate for the application, and whether to suspect issues with studies/products that use those data. Ease of reproducibility.","['IdentifyVulnerabilities', 'BetterDataSelection', 'Reproducibility']"
"I would hope that DataBOMs include some kind of predataanalysis so I can get a good feeling of the data contained without having to inspect the data myself too much.Besides that, I want to be able to look up the exact versioning  being able to transform the data in different ways ","['DataAnalysis', 'DataVersioning']"
An example of usage for the model,['ExampleModelUsage']
Quality Control,['BetterDataSelection']
Model validation and testing. Comparing production environment metrics with Authors results.,"['ValidationAndTesting', 'Reproducibility']"
Benefits include better ability to detect biases and increased reproducibility of results.,"['Reproducibility', 'IdentifyVulnerabilities']"
Some kind of guarantees of the model performance.,['GuaranteesOnModelPerformance']
"If a widespread dataset poisoning attack was ever actually performed, it would be easier to figure out which models are affected.",['IdentifyVulnerabilities']
. Prevent abuse of the dataset. Help to protect the IP both the source of the raw data and the processed dataset,"['PreventDataAbuse', 'ProtectIP']"
"Solving data poisoning issues, reproducibility issues","['Reproducibility', 'IdentifyVulnerabilities']"
It would help increase the trust in the model.,['IncreasedModelTrust']
I dont know.,['Unsure']
Better sense of the biases in datasets,['IdentifyVulnerabilities']
Idendity with more ease biases that could emerge from the dataBetter classify the data,"['BetterLabeling', 'IdentifyVulnerabilities']"
"Better traceability, versioning, reproducibility of studies","['IdentifyVulnerabilities', 'Reproducibility', 'DataVersioning']"
"First and foremost, help manage compliance risk",['Compliance']
"Some of the fields that would ideally be present are difficult to complete, requiring domain specific knowledge. If Im good with image models and happen to also want to propose a new dataset, it is difficult for me alone to do all the analysis to create a full DataBOM. I will need people experienced in different domains, such as ethics, data science, and data visualization.",['FillingFields']
Ridged requirements are always annoying when they dont apply to your work. Enforcing a standard will likely hurt innovation more than help it.,['RigidRequirements']
Getting dataset creators to fill them in. Should be automated as much as possible.,['DatasetCreatorsMakingThem']
Companies not willing to release some information particularly around data collection.The potential threat of malicious actors using this information to find loop holes they can exploit.,"['IPandPrivacy', 'Security']"
Terminologies and standards used to reduce ambiguity in the BOMs are probably lacking.,['LackingStandards']
"Finding a good mix between accurate versioning and many updates. I would want to be able to access any version I trained a model with (or used some kind of data analysis on) but I would not like to have an updated version whenever I updated a single label (because then there would be thousands of versions if I update thousands of labels in a short time period).I also would like to be able to automatically check labeled data so I can inspect possible structural labeling errors as soon as possible (e.g. detect that something is marked as a date that is not parseable as a date, or having an invoice where the uid is not labeled).In general I would expect any DataBOM being well integrated with a labeling tool  at best with several of the opensource labeling tools available  while not forcing to use exactly that tool.","['VerifyData', 'Versioning', 'Updating']"
Theyre heavy and the distribution will be complicated because of it,"['Size', 'Distribution']"
Maintenance,['Updating']
Data privacy and security.,"['IPandPrivacy', 'Security']"
"A major risk is that the BOM becomes yet another bureaucratic nightmare involving more and more documents to fill out, without actually solving the underlying problem.",['WorthlessComplianceDocument']
"The license, GDPR, uncertainty factors, etc. ","['IPandPrivacy', 'Regulation']"
"It seems like DataBOMs would only be possible by using some central tool that manages all data fed into a model so that adhoc data (for example, from other files on disk) isnt trained into the model without being tracked.",['TrackingAllTrainingData']
. Hard to define fields for describing different data in a standard way. Hard to verify the effectiveness of the data,"['VerifyData', 'LackingStandards']"
Size and versioning,"['Size', 'Versioning']"
"The main challenges regard sensitive, personally identifiable, and private information, in general. Having a comprehensive DataBOM when such data are involved might be infeasible for privacy reasons. As an alternative, it might be necessary to provide a lower quantity of information (even aggregated).",['IPandPrivacy']
"There should be a mechanism to carry and show image hash with each image. Sometimes, images may seem that they are exactly the same but their hash values are different.",['DataHash']
Many datasets are labeled by volunteers or untrusted folks (e.g. Amazon Mechanical Turk) and it is hard to formally represent those characteristics or interpret them.,['RepresentLabelers']
The maintenance of keeping them uptodate.,['Updating']
Standardizing the format and the adoption,"['Adoption', 'LackingStandards']"
Documenting sources and methods Maintaining sources and methods Synthesizing descriptions Maintaining descriptions,"['Documentation', 'Maintenance']"
"again, by making a communitywide push for these thing. I believe that the neurips dataset track requires a dataset card to be submitted alongside the paper, which includes some basic parts of a dataBOM. Expanding this requirement and the contends of this dataset card should help increase the use of DataBOMs.","['AcademicRequirements', 'Adoption']"
Create a legal liability for misrepresenting data.,['LegalRequirements']
Perhaps requiring them to publish papers in conferences and journals.,['AcademicRequirements']
Having an independent community or board that checks.,['TrustedThirdParty']
Require validation of the BOM using a standardized validation tool upon submission to whatever system will store the data.,"['ValidationTools', 'AutomaticValidation']"
"hashing the data so I can check for modifications, ensuring that the dataset is complete and contains the data fields mentioned above, ",['CryptographicVerification']
Just using a CICD action that runs some tests,"['AutomaticValidation', 'ValidationTools']"
Data Governance,['DataGovernance']
"Reproducing results by trusted third party. That can be partial, like validation data only.",['TrustedThirdParty']
Cryptographic hash functions of the data can help ensure that the version is in fact what they say it is.,['CryptographicVerification']
"Documentation, rigourous testing, formalization. ","['FormalMethods', 'Documentation', 'Testing']"
Somebody would have to design a canonical training procedure that defines a process for generating approved dataset files that get read and verified somehow during the training process to make sure no unknown/outside data is used to train a model,['StandardizedProcedures']
"I am not sure about this part, traditional data quality may help to ensure components of the dataset partially.","['TraditionalMethods', 'Unsure']"
"Again, provenance",['ProvenanceInformation']
Not sure this is feasible when private information used.,['Impossible']
I dont know.,['Unsure']
"I guess if you are using ML for data labeling, you could make some progress. With human annotation it seems impossible to fully characterize.",['Impossible']
I am not sure.,['Unsure']
"Create automated tools that support the validation, standardization, upgrade, and audit of the DataBOMs.","['ValidationTools', 'AutomaticValidation', 'AuditTooling', 'UpgradeTooling']"
Trust Clever application of zeroknowledge proofs Build data integrity with what Christian Catalini calls costless verification,"['ZeroKnowledgeProof', 'CostlessVerification']"
"increased reproducibility, easier iteration on previous works, more accessible resources, earlier detection of weaknesses/vulnerabilities.","['Security', 'OpenAccess', 'Reproducability', 'ImprovedIteration']"
It will provide structure to help people document their work.,['BetterDocumentation']
Similar answer to DataBOMs.,"['Reproducibility', 'IncreasedTransparency']"
This would help developers not involved in the project have a better understanding of the software they are working with.,['Teaching']
"Unsure, not experienced enough with them.",['Unsure']
"Idealy I dont have to implement features like versioing manually myself, and even get inspired to use techniques that I usually dont think of myself (e.g. I would have never written code to monitor the GPU memory usage or GPU compute utility while training, even if I didnt have a tool that would monitor it for me.) and therefore ensure that I am using best practices or to be more concrete, my colleagues with lesser experience use best practices without me having to tell them everything :)","['BestPractices', 'Automation']"
An example of usage for the model...,['ExampleModelUsage']
Reproducibility,['Reproducability']
Reducing security risks.Making deployment/updates faster.,"['Security', 'FasterDeployment']"
"As with DataBOMs, one big benefit is the ability to better detect biases and reproduce results.","['Reproducability', 'DetectBiases']"
The secure and safe usage in critical domains.,['Security']
People using models would be able to more easily discover issues with the models theyre using.,['ProblemLocation']
"Mostly the same as the DataBOM, it helps to verify the usability of the AIBOMs and helps to identify the potential issues and risks.","['Security', 'ProblemLocation', 'VerifyUsability']"
Trustworthy  against supply chain type of attacks,"['Security', 'Trust']"
"As for the DataBOM, it would help increase the trust in the model.",['Trust']
No comment,['BadAnswer']
"Might help with the socalled reproducibility crisis in AI, though frankly Im skeptical. I think the bigger benefit would be a CVElike reporting of bias in datasets that let us see which models should be updated.","['Reproducability', 'DetectBiases']"
Continous Integration of AI models,['ContinuousIntegration']
"Similarly to dataBOMs, it could help with reproducing studies, better collaboration, faster iteration and improvements of model. Bugs, biases, and fairness issues could be discovered quickly","['ProblemLocation', 'ImprovedIteration', 'DetectBiases', 'Reproducability', 'BetterCollaboration']"
"First and foremost, help manage compliance risk",['Compliance']
"Time consuming, requires developers to write documentation, may require domain specific knowledge and specific or niche skillsets","['TimeConsuming', 'Documentation', 'DomainSpecificKnowledge']"
It is hard to anticipate how an imposed structure will hinder someones work.,['TooStructured']
Similar answer to DataBOMs.,['Adoption']
Companies not willing to release information.Malicious actors taking advantage this information to find vulnerabilities,"['WithholdingInformation', 'Security']"
"Unsure, not experienced enough with them.",['Unsure']
"There needs to be some trade off between working out of the box and being customizable. For example at work we are currently using ClearML for training and monitoring, however ClearMLs documentation is mostly you dont need to do anything, we do everything for you, they are applying a lot of features we dont need/want while failing to do other things  like tracking metrics on a custom training loop  automatically. Then their documentation is not very good, as they expect their users to do the exact usecase they described, using certain training libraries. Making it more complicated to manually add metrics you want to add (although the solution was easy after knowing what the solution was)A good tool would make clear if it goes all in on acertain tool chain or  as I would prefer  make it easy to adapt it to any training I want, giving me options to adapt on several ways so I can choose the adoption that is the easiest for me.","['UseCases', 'CustomizableTools']"
Theyre heavy so it will be complicated to deliver them...,"['Size', 'Distribution']"
Standardization,['Standardization']
Training dataset is usually large and top secret of a company. Its hard to involve some third party here. Solving that may require some new laws.,"['EnsureConfidentiality', 'WithholdingInformation', 'Size']"
"Also as with DataBOMs, a major risk is that it increases paperwork without actually solving the underlying problem.  Requiring AIBOMs could create a quagmire of red tape.","['TimeConsuming', 'NotUseful']"
"Common standard, diverse use cases, confidentiality of data. ","['EnsureConfidentiality', 'UseCases', 'Standardization']"
"If creation of an AIBOM requires manual effort on the part of the people creating the model, its likely not going to be widely adopted. It may be difficult to adopt any new process if it adds significant friction between the action of retrieving data and using it in training the model.","['Adoption', 'TimeConsuming']"
"Hard to verify the correctness of the claimed dependencies, especially for big models. With more common AI services like OpenAI APIs provided as a part of software development, many of these services are hidden, and difficult for the public to check their risks and issues. Even its users and developers hardly understand what will be the data and ML process it will invoke.","['WithholdingInformation', 'VerifyDependencies']"
"Size, versioning","['Versioning', 'Size']"
No particular challenge.,['NoChallenges']
Some may see as not needed information.,['NotUseful']
"We barely use SBOMs, and AIBOMs will be harder.",['Adoption']
Making them work on many different AI models/systems.,['CrossModel']
Adoption of these systems by large organizations. The continuous evolution and changes in the models could make them obsolete quite quickly.,"['Adoption', 'ObsoleteQuickly']"
Documenting methods Maintaining methods Synthesizing descriptions Maintaining descriptions,"['Documentation', 'Maintenance']"
"I think they should echo the latest legal stances from different jurisdictions, as well as any personal opinions/objections the authors may have to particular uses of a dataset.","['UseCaseSpecific', 'AuthorOpinion', 'DeferToLegalSystem']"
"If the AIBOM specifies that there is no issue with licensed material and there turns out to be an issue, then the legal liability will rest with the creator of the AIBOM who misrepresented the claims.",['BOMCreatorLiable']
Maybe provide a license information for each data source. Also provide information allowing data owners to opt out from scrapping.,"['OptOut', 'ProvideSourceLicenses']"
All areas where data is sourced from should be included,['ProvideSources']
Im unsure due to lack of expertise in this area.,['Unsure']
"I am not sure if they should, however I am also not deep in the copyright debate, as I usually use customer data I got permission to use.",['ShouldNotAddress']
We should always attach a license to insure if the author wants this he will be able to make the person using his data illegally to stop or get punished,"['AuthorOpinion', 'ProvideSourceLicenses', 'BOMCreatorLiable']"
Getting the copyright holders approval or using opensource software,['UseMaterialsLegally']
"If such data is used, the methodology should be described. Would be also nice to have some proofoflegaluse document included.","['ProvideSourceLicenses', 'UseMaterialsLegally']"
"Ive brought up this issue for years, but no one has ever wanted to discuss it.  Terms of Service and licenses can forbid the practice, but it happens anyway.  In theory, an AIBOM could require builders of AI systems to disclose that a system was trained using licensed data, but I suspect there would be rampant violation of the requirement.  No one wants to admit that their new AI system works well because it copies creative effort.",['DiscloseLicensedData']
Not sure.,['Unsure']
"If using external copyrighted data, the Data BOM should include the URL the data was scraped from and timestamp of when the data was scraped.In an ideal world, there would be some system copyright owners could use to determine if their copyrighted data was included in the dataset. If so, they should be entitled to know what portion of their copyrighted data was used (i.e. they should be able to see and download their data from the training dataset).","['ProvideTimestamp', 'ProvideSources', 'DataOwnersCanCheck']"
". The presence of licensed material, and what licenses. Will this be a conflict of interest and infringement of copyrights to the original licensed material?. If these materials are processed, will the personal information/identification (e.g., human face, drawing style) be able to be retrieved and recognized?","['ConflictOfInterest', 'DiscloseLicensedData', 'DisclosePII', 'ProvideSourceLicenses']"
Follow the license requirement. But I also think some license needs updates.,['UseMaterialsLegally']
"It should explicitly report the licenses of the used material, when relevant.",['ProvideSourceLicenses']
Can be a part of an image like PPM,['PartOfImage']
The creators of datasets are responsible for honoring licenses. Governments should introduce legislation and/or regulation to enforce this  GDPR etc.,"['UseMaterialsLegally', 'BOMCreatorLiable']"
"They should identify and group the licenses, and report them to the developer so that he or she can exclude the data or contact the person owning the license",['ProvideSourceLicenses']
Automate the screening process and report warnings about possible license infringement,['AutomatedScreening']
I think this question is too broad :,['BadAnswer']